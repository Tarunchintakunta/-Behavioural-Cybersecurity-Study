\section{Design and Architecture}
\label{sec:design}

This chapter describes the system architecture and the data processing pipeline designed to analyze the collected data and train the predictive models.

\subsection{System Architecture}
The research framework is built upon a modular architecture comprising three main components: Data Ingestion, Data Processing, and Model Development.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.8\textwidth]{figures/system_architecture.png}
%     \caption{High-Level System Architecture}
%     \label{fig:architecture}
% \end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/research_framework.png}
    \caption{Research Framework: Integrating Data Collection, Processing, and Modeling}
    \label{fig:framework}
\end{figure}

\begin{itemize}
    \item \textbf{Data Ingestion Layer}: Responsible for collecting raw data from the survey platform (CSV export) and the phishing simulation tool (log files).
    \item \textbf{Data Processing Layer}: Handles data cleaning, standardization, merging, and feature engineering. This layer transforms raw inputs into a structured dataset suitable for machine learning.
    \item \textbf{Model Development Layer}: Includes the training, validation, and testing of various machine learning algorithms. It utilizes MLflow for experiment tracking and model versioning.
\end{itemize}

\subsection{Data Processing Pipeline}
The data processing pipeline, implemented in Python, is critical for ensuring data quality. The key steps are as follows:

\subsubsection{Data Cleaning and Standardization}
Raw data often contains inconsistencies. The \texttt{preprocess\_for\_modeling.py} script performs the following operations:
\begin{itemize}
    \item \textbf{Participant ID Standardization}: To merge survey and experiment data, a common key is required. The script standardizes participant IDs to a \texttt{PXXX} format (e.g., P001, P042), handling variations in input formats (e.g., "Participant 1", "p1").
    \item \textbf{Missing Value Imputation}: Numerical features with missing values are imputed using the median, while categorical features are imputed using the mode. This prevents data loss and ensures the models can handle incomplete records.
\end{itemize}

\subsubsection{Feature Engineering}
Raw survey responses were transformed into quantitative scores to serve as model features:
\begin{itemize}
    \item \textbf{Cognitive Bias Score}: Aggregated score from the bias-related questions, normalized to a 0-1 scale.
    \item \textbf{Stress Level Score}: Derived from the Perceived Stress Scale questions.
    \item \textbf{Multitasking Habits Score}: Derived from the Media Multitasking Index questions.
    \item \textbf{Vulnerability Score}: The target variable. A binary classification was used: 1 (Vulnerable) if the user clicked the phishing link, and 0 (Resilient) otherwise.
\end{itemize}

\subsubsection{Data Merging}
The cleaned survey dataframe (features) and the experiment dataframe (labels) are merged using an inner join on the standardized \texttt{participant\_id}. This results in a final dataset where each row represents a unique participant with their corresponding psychological profile and behavioral outcome.

\subsection{Machine Learning Workflow}
The machine learning workflow follows standard best practices:
\begin{enumerate}
    \item \textbf{Data Splitting}: The dataset is split into a training set (80\%) and a testing set (20\%). Stratified sampling is used to ensure the class distribution (vulnerable vs. resilient) is preserved in both sets.
    \item \textbf{Preprocessing}: Categorical variables (e.g., Job Role) are encoded using Label Encoding. Numerical variables are scaled if necessary (though tree-based models are generally robust to unscaled data).
    \item \textbf{Model Selection}: Four candidate models were selected for evaluation:
    \begin{itemize}
        \item Logistic Regression (Baseline)
        \item Random Forest Classifier
        \item Gradient Boosting Classifier
        \item Support Vector Machine (SVM)
    \end{itemize}
    \item \textbf{Experiment Tracking}: MLflow is integrated to log hyperparameters, metrics (Accuracy, Precision, Recall, ROC AUC), and artifacts (confusion matrices, ROC curves) for each run, ensuring reproducibility.
\end{enumerate}
